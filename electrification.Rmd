---
title: "R Notebook"
output: Comercial Building Working Group TG2 Scaling Electrificaiton  
---


```{r, echo="FALSE", include=FALSE, message=FALSE}

###############################################################################
#                             Set up environment                                #
###############################################################################

my_packages <- c("tidyverse", "lubridate", "fable", "tsibbledata", "ggplot2", "forecast", "tseries", "rio", "zoo", "readxl", "tsibbledata") 
lapply(my_packages, require, character.only = TRUE)

#Choose one working site:
 place <- "Home"
#place <-  "work"

#Set proper working Dir 
if (place == "Home"){setwd("C:/Users/paulr/Documents/R/cbwg")} else
{setwd("C:/Users/prode/Documents/R/cbwg")}

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")}

rm(place, my_packages )
  
```


The goal with this data project is to use the LL84 benchmarking to identify the thermal potential in each of the building typologies. 
1. Identify the kBTU's of gas, oil and district steam used (thermal fuel) in the commercial stock.
2. Allocate the thermal fuel among building typologies. 
3. Show ranking of typologies by sf and thermal fule volumn. 
3. Show steam in manhattan as a breakout. 



```{r, echo="FALSE", include=FALSE, message=FALSE}

# Read in LL84 data for 2017, change feature names, and zero out NA's

L84_2017a <- read_excel("data/2017_nyc_benchmarking.xlsx", sheet = "Information and Metrics", col_names = TRUE, na = "NA"  ) %>%   
  mutate(Data = "Information and Metrics") %>% 
  data.frame() %>% 
  select("Property.Id", "Property.Name", "BBL...10.digits", "NYC.Building.Identification.Number..BIN.", "Address.1..self.reported.", "Postal.Code", "Borough", "Self.Reported.Gross.Floor.Area..ft².", "List.of.All.Property.Use.Types.at.Property", "Year.Built", "Number.of.Buildings", "Site.EUI..kBtu.ft².","Fuel.Oil..1.Use..kBtu.", "Fuel.Oil..2.Use..kBtu.",       "Fuel.Oil..4.Use..kBtu.", "Fuel.Oil..5...6.Use..kBtu.", "Diesel..2.Use..kBtu.",        "Propane.Use..kBtu.", "District.Steam.Use..kBtu.", "District.Hot.Water.Use..kBtu.",    "District.Chilled.Water.Use..kBtu.","Natural.Gas.Use..kBtu.", "Electricity.Use...Grid.Purchase..kBtu.", "Electricity.Use...Grid.Purchase..kWh.")

L84_2017b <- read_excel("data/2017_nyc_benchmarking.xlsx", sheet = "Multi-BBL", col_names = TRUE, na = "NA"  ) %>%   
  mutate(Data = "Multi-BBL") %>% 
  data.frame() %>% 
  select("Property.Id", "Property.Name", "BBL...10.digits", "NYC.Building.Identification.Number..BIN.", "Address.1..self.reported.", "Postal.Code", "Borough", "Self.Reported.Gross.Floor.Area..ft².", "List.of.All.Property.Use.Types.at.Property", "Year.Built", "Number.of.Buildings", "Site.EUI..kBtu.ft².","Fuel.Oil..1.Use..kBtu.", "Fuel.Oil..2.Use..kBtu.",       "Fuel.Oil..4.Use..kBtu.", "Fuel.Oil..5...6.Use..kBtu.", "Diesel..2.Use..kBtu.",        "Propane.Use..kBtu.", "District.Steam.Use..kBtu.", "District.Hot.Water.Use..kBtu.",    "District.Chilled.Water.Use..kBtu.","Natural.Gas.Use..kBtu.", "Electricity.Use...Grid.Purchase..kBtu.", "Electricity.Use...Grid.Purchase..kWh.")
L84_2017a$BBL...10.digits <- as.character(L84_2017a$BBL...10.digits)

#combine datasets deleting duplicates and remove import files
union(L84_2017a, L84_2017b) -> L84_2017
remove("L84_2017a", "L84_2017b")
L84_2017$List.of.All.Property.Use.Types.at.Property <- as.factor(L84_2017$List.of.All.Property.Use.Types.at.Property)


#Add GSF bins to identify where bulk of sf is by GSF ranges 50,000 up to over 500k.
c <- c("0 to 50,000", "50,000 to 100,000", "100,000 to 500,000", "500,000 to 1,000,000", "over 1,000,000")
L84_2017$bins <- cut(L84_2017$`Self.Reported.Gross.Floor.Area..ft².`, breaks = c(0,50000, 100000, 500000, 1000000, 9000000), dig.lab = 7 , ordered_result = TRUE, labels = c ) 
d <- c("pre 1942", "1942 to 1980", "1980 to 2000")
L84_2017$Year.Range <- cut(L84_2017$Year.Built, breaks = c(0, 1942, 1980, 2021),dig.lab = 4, labels = d)
remove(c,d) #clean up environment


# Add total thermal which is the sum of all thermal fuels. 

L84_2017 %>% rowwise() %>%  mutate("Total.Thermal (kBTU)" = sum(Fuel.Oil..1.Use..kBtu., Fuel.Oil..2.Use..kBtu., Fuel.Oil..4.Use..kBtu. , Fuel.Oil..5...6.Use..kBtu.,  Diesel..2.Use..kBtu. , Propane.Use..kBtu. , District.Steam.Use..kBtu. , District.Hot.Water.Use..kBtu. + District.Chilled.Water.Use..kBtu. , Natural.Gas.Use..kBtu., na.rm = TRUE) ) -> L84_2017

# Calculate Site EUI to compare to vales in the data frame
L84_2017 %>% mutate("EUI" = ifelse(is.na(Electricity.Use...Grid.Purchase..kBtu.), (`Total.Thermal (kBTU)`)/ `Self.Reported.Gross.Floor.Area..ft².`, (Electricity.Use...Grid.Purchase..kBtu. + `Total.Thermal (kBTU)`)/ `Self.Reported.Gross.Floor.Area..ft².`)) -> L84_2017


# Remove bad data using following rules: 
  #(1) Rows with 0 buildings. 
  #(2) remove rows with EUI = 0 
  #(3) remove bad 65 Broadway Manhattan and 290 Wallabout Street Brooklyn - bad data 
  #(4) remove buildings with year built < 1800
  
L84_2017 %>% filter(`Self.Reported.Gross.Floor.Area..ft².` >= 25000) %>%
  drop_na(`Site.EUI..kBtu.ft².`) %>%
  filter(Property.Name != "65 broadway llc") %>%
  filter(Property.Name != "290 Wallabout St") %>%
  filter(Year.Built > 1800) -> L84_2017


L84_2017 %>% filter(`Site.EUI..kBtu.ft².` < 500) %>%
  ggplot(aes( `Site.EUI..kBtu.ft².`)) +
  geom_histogram()


L84_2017 %>% filter(`Site.EUI..kBtu.ft².` < 500) %>%
  ggplot(aes( x = Year.Built, y = EUI)) +
  geom_point()




GSF_bins <- L84_2017 %>%
  group_by(Catagory, bins) %>%
  summarise(GSF = sum(GSF), Num.Buildings = n(), 'Thermal (MMBtu)' = sum(total.thermal)/1000, `Electric (MMBtu)` = sum(`Electric (kBtu)`)/1000) %>% mutate(`Thermal (kBTU/GSF)` = `Thermal (MMBtu)`/GSF)
GSF_bins$`Thermal (MMBtu)` <- format(GSF_bins$`Thermal (MMBtu)`, big.mark = ",", digits = 0, scientific = FALSE)
GSF_bins$`Electric (MMBtu)` <- format(GSF_bins$`Electric (MMBtu)`, big.mark = ",", digits = 0, scientific = FALSE)
GSF_bins$`Thermal kBTU/GSF` <- format(GSF_bins$`Thermal MMBTU/GSF`, big.mark = ",", digits = 2, scientific = FALSE)

GSF_bins_dates <- L84_2017 %>%
  group_by(Catagory, bins, Dates) %>%
  summarise(GSF = sum(GSF), Num.Buildings = n(), 'Thermal (kBtu)' = sum(total.thermal), `Electric (kBtu)` = sum(`Electric (kBtu)`)) 

L84_2017 %>% filter(Catagory != "Multifamily Housing") -> trial1
  summary()


# Remove outliers for gsf NGas and Electric Usage
take.out <- 10
L84_2017 %>% arrange(GSF) -> L84_2017
L84_2017[take.out:(nrow(L84_2017)-take.out),] -> L84_2017
L84_2017 %>% arrange(`NGas (kBtu)`) -> L84_2017
remove(take.out)


GSF_bins_dates %>% filter(Catagory == "Office")






```

 Ge these plots in the report
 8/20/2021 CBWG TG7-2
Plot the following
mmbtu v gsf - points color on fuel type.  
mmbtu/gsf v year bin - points + color on category. 
mmbtu/gsf v decade - points + color on category. 
mmbtu/gsf v gsf - points
mmbtu/gsf v cartagory - points

mmbtu/gsf v fuel type. 


```{r, echo="FALSE", include=FALSE, message=FALSE}

ggplot(L84_2017, aes(Catagory)) +
  geom_bar() +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```











```{r, echo=FALSE}
#Before making time series be sure the order is right and make a clean count feature. 
E <- E[order(E[,"Date"]),]
E_ts = ts(E[, c("kWh")])
E$clean_count = tsclean(E$'kWh')
plot(E_ts)


#Running the decompose function with both additive and Multiplicative. With additive being Ts = Seasonal + Trend + Random, and multiplicative being Ts = Seasonal x trend x random. 



#Read in the steam data. 
S <- read_csv("C:/Users/paulr/Documents/R/EnergyForecasting/data/MACH Energy - Data (S).csv", skip = 0, na = "Not Available") 

#Before making time series be sure the order is right and make a clean count feature. 
S <- S[order(E[,"Date"]),]
S_ts = ts(S[, c("Value")])
S$clean_count = tsclean(S$'kWh')
plot(S_ts)


```

Model specifications and estimation.
ETS(tsibble, formulam ...)
ARIMA(tsibble, formula, ...)
TSLM(tsibble, formula, ...)
and many more. 

Model specification with formulas. 
Exmaple: transformation(y) ~ trend() + season(period="day") + X
Like the lk() function rules. 

LHS: Responce
Defines the data's responce variable
Specificaiton of transformations (with automatic back transformation)

RHS: Specials
Model specific specia functions
Exogenous regressors 


Plotting temperutere on time and demand on time and stacking to show visually relationships is recomended. 

tsbl_elec <- tsibbledata::vic_elec %>% filter(Date < ymd("2014-03-01"))
fbl_elec_fit <- tsbl_elec %>%
  model(ARIMA(Demand ~ WorkDay + Temperature + I(Temperature^2),
  pdq(1,0,1) + PDQ(1,1,1, period = "day")))

# # A mable: 1 model
# model
# <model>
# 1LM w/ ARIMA(1,0,1)(1,1,1)[48] erros 


Extract model information using tidy funcitons using the broom package
augment(mable, ....)
tidy(mable, ...)
glance(mable, ...)
components(mable, ...)

Intresting plot can be made using these.
components(fbl_cafe_fit) %>%
  gather(component, value, level, slope, season) %>%
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(vrs(component), scales = "free_y")
  

Forcast future values
forcast(mable, new_data, h, ...)
Example: fit_cafe_fc <- fbl_cafe_fit %>% forcast(h=24)
fbl_cafe_fc %>% autoplot(vic_cafe)


Electric Demand example
tsbl_elec_new <- tsibbledata::elecdemand %>% 
  filter(index >= ymd("2014-03-01"), index < ymd("2014-03-14"))
fbl_elec_fc <- fbl_elec_fit %>%
  forecast(tsbl_elec_new)

fbl_elec_fc %>% autoplot(tsbl_elec)


  
```{r}
tsbl_elec <- tsibbledata::vic_elec %>% filter(Date < ymd("2014-03-01")) %>% mutate("WorkDay" = wday(Date) )


fbl_elec_fit <- tsbl_elec %>%
  model(arima = ARIMA(Demand ~ WorkDay + Temperature + I(Temperature^2)))
        #, pdq(1,0,1) + PDQ(1,1,1, period = "day"))



tsbl_elec_new <- tsibbledata::vic_elec %>% 
  filter(Date >= ymd("2014-03-01"), Date < ymd("2014-03-14"))


fbl_elec_fc <- fbl_elec_fit %>%
  forecast(tsbl_elec_new)

view(vic_elec)
view(tsbl_elec_new)
```


Accurach evaluation to compare models 
accuracy(mable, measures, ...)
accuracy(fable, new_data, measures, ...)

fbl_cafe_fit %>% accuracy()

Or

fbl_elec_fc %>% accuracy(tsbl_elec_new)


This makes 152 models. 
fbl_cafe_fit 
retail_ets <- tsibbledata::ausretail %>
  ETS(Turnover)


Now use 

Extract(broom::augment)
augment(retail_ets) 

Extract(broom::tidy)
tidy(retail_ets)

Extract(broom::glance)
glance(retail_ets)

Extract(fable::components)
components(retail_ets)

Example:
components(retail_ets) %>%
  filter(Industry == "Cafes, restaurants and takeaway food services") %>%
  ggplot(aes(x = Month, y = level, color = State)) +
  geom_line()
  

Forecast
retail_fc <- retail_ets %>% forecast(h=24)

Evaluate 
retail_ets %>% accuracy()
measures? to check difference in accuracy maybe? 
```{r}

```

Forecasting with Fasster showing electric 

fasster_fit <- tsbl_elec %>%
  fasster(log(Demand) ~ WorkDay %S% (trig(48,16) + poly(1)) + Temperture + I(Temperture^2)) 
  
using exoginest regressors for workday and temperture.

fasster_fc <- fasster_fit %>% 
  forecast(tsbl_elec_new) 
  
  fasster_fc %>% 
    autoplot(tsbl_elec)
    
```{r}


```


Coming Simulate() future paths 

set.seed(20181108)
vic_cafe_sim <- fbl_cafe_fit %>%
  simulate( h = 24, times = 5)
  
  
vic_cafe %>% 
  filter(year(Month) >= 2021) %>% 
  autoplot(Turnover) + 
  geom_line(aes(y = .sim, group = .rep), alpha = 0.3, data = vic_cafe_sim)
  
  
Feture: interpolate() missing values

tsibbledata::olympic_running 

fit a model then interpolate.

olympic_complete <- olympic_running %>% 
  TSLM(Time ~ trend()) %>%
  interpolate(olympic_running) 
  
  refit() allows a model to be applied to a new dataset
  stream() allows a model to be extended using new data
  
  stream is good when you have a model and get additional time series data you just add it and the modeling is redone. 
  
  fasster_stream <- fasster_fit %>% stream(tsbl_elec_new) 
  
Decomposition forecasting
library(tsibblestats)
cafe_dcmp <- vic_cafe %>% STL(log(Turnover)) 


Interval and distribution accuracy
fbl_elec_fc %>% 
accuracy(
  new_data = tsbl_elec_new,
  measures = list(winkler = winkler_score, percentile = perentiale_score)
  
  
)