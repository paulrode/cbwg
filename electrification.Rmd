---
title: "R Notebook"
output: Comercial Building Working Group TG2 Scaling Electrificaiton  
---


```{r, echo="FALSE", include=FALSE, message=FALSE}

###############################################################################
#                             Set up environment                                #
###############################################################################

my_packages <- c("tidyverse", "lubridate", "fable", "tsibbledata", "ggplot2", "forecast", "tseries", "rio", "zoo", "readxl", "tsibbledata") 
                 
lapply(my_packages, require, character.only = TRUE)

#Choose one working site:
place <- "Home"
# place <-  "work"

#Set proper working Dir 
if (place == "Home"){setwd("C:/Users/paulr/Documents/R/cbwg")} else
{setwd("C:/Users/prode/Documents/R/cbwg")}

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")}

rm(place, my_packages )
  
```






```{r, echo="FALSE", include=FALSE, message=FALSE}

# Read in LL84 data 


L84_2017 <- read_excel("data/2017_nyc_benchmarking.xlsx", sheet = "Information and Metrics", col_names = TRUE, na = "NA"  ) %>%   mutate(Year = 2017) %>% data.frame()%>% select(Year, `BBL...10.digits`, NYC.Building.Identification.Number..BIN.,
Largest.Property.Use.Type, Self.Reported.Gross.Floor.Area..ft². , Address.1..self.reported., Borough, Year.Built, Natural.Gas.Use..kBtu., Electricity.Use...Grid.Purchase..kBtu., Fuel.Oil..1.Use..kBtu., Fuel.Oil..2.Use..kBtu. , Fuel.Oil..4.Use..kBtu. , Fuel.Oil..5...6.Use..kBtu. )

colnames(L84_2017) <- c("Year", "BBL", "BIN", "Catagory", "GSF", "Address", "Borough", "Built", "NGas (kBtu)", "Electric (kBtu)" , "1 Oil (kBth)", "2 Oil (kBth)", "4 Oil (kBth)", "6 Oil (kBth)")

L84_2017[is.na(L84_2017)] <- 0
L84_2017$Catagory <- as.factor(L84_2017$Catagory)

summary(L84_2017)

L84_2017.duplicates <- L84_2017[duplicated(L84_2017),]
L84_2017 <- unique(L84_2017)
str(L84_2017)

L84_2017_by.catagory <- L84_2017 %>% group_by(Catagory) %>% summarise(SF = sum(GSF), NGas = sum(`NGas (kBtu)`), Elect = sum(`Electric (kBtu)`))


L84_2017_by.catagory_total <- L84_2017_by.catagory %>% summarise(SF = sum(SF), NGas = sum(NGas), Elect = sum(Elect))







L84_2016 <- read_excel("data/2016_nyc_benchmarking.xlsx", sheet = "Information and Metrics", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2016) %>%  data.frame() %>% select(Year, `BBL...10.digits`, NYC.Building.Identification.Number..BIN.,
Largest.Property.Use.Type, DOF.Gross.Floor.Area , Address.1..self.reported., Borough, Year.Built, Natural.Gas.Use..kBtu., Electricity.Use...Grid.Purchase..kBtu., Fuel.Oil..1.Use..kBtu., Fuel.Oil..2.Use..kBtu. , Fuel.Oil..4.Use..kBtu. , Fuel.Oil..5...6.Use..kBtu. )
colnames(L84_2016) <- c("Year", "BBL", "BIN", "Catagory", "GSF", "Address", "Borough", "Built", "NGas (kBtu)", "Electric (kBtu)" , "1 Oil (kBth)", "2 Oil (kBth)", "4 Oil (kBth)", "6 Oil (kBth)")


 

L84_2015 <- read_excel("data/2015_nyc_benchmarking.xlsx", sheet = "2015 Data Reported in 2016", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2015)  %>% data.frame()  %>% select(`NYC.Borough..Block.and.Lot..BBL.`, "gsf" = Largest.Property.Use.Type...Gross.Floor.Area..ft².)


L84_2014 <- read_excel("data/2014_nyc_benchmarking.xlsx", sheet = "WORKING FILE", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2014) %>%  data.frame() %>%
  select('NYC.Borough..Block..and.Lot..BBL.', "gsf" = Reported.Property.Floor.Area..Building.s....ft².)

L84_2013 <- read_csv("data/2013_nyc_benchmarking.csv", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2013) %>%  data.frame() %>%
  select(BBL,"gsf" = DOF.Property.Floor.Area..Buildngs.and.Parking..ft2. , "type" = Primary.Property.Type...Self.Selected)

L84_2012 <- read_csv("data/2012_nyc_benchmarking.csv", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2012) %>%  data.frame() %>%
  select(BBL, "gsf" = Property.Floor.Area..Buildngs.and.Parking..ft2.)

L84_2011 <- read_excel("data/2011_nyc_benchmarking.xls", sheet = "Energy and Water Data Disclosu", col_names = TRUE, na = ""  ) %>%   mutate(Year = 2011) %>%  data.frame() %>%
 select(BBL, "gsf" = Reported.Building.Square.Footage)



```


```{r, echo="FALSE", include=FALSE, message=FALSE}

ggplot(L84_2017, aes(Catagory)) +
  geom_bar() +
  coord_flip(ylim = c(0,1000), expand = TRUE, clip = "on")


```











```{r, echo=FALSE}
#Before making time series be sure the order is right and make a clean count feature. 
E <- E[order(E[,"Date"]),]
E_ts = ts(E[, c("kWh")])
E$clean_count = tsclean(E$'kWh')
plot(E_ts)


#Running the decompose function with both additive and Multiplicative. With additive being Ts = Seasonal + Trend + Random, and multiplicative being Ts = Seasonal x trend x random. 



#Read in the steam data. 
S <- read_csv("C:/Users/paulr/Documents/R/EnergyForecasting/data/MACH Energy - Data (S).csv", skip = 0, na = "Not Available") 

#Before making time series be sure the order is right and make a clean count feature. 
S <- S[order(E[,"Date"]),]
S_ts = ts(S[, c("Value")])
S$clean_count = tsclean(S$'kWh')
plot(S_ts)


```

Model specifications and estimation.
ETS(tsibble, formulam ...)
ARIMA(tsibble, formula, ...)
TSLM(tsibble, formula, ...)
and many more. 

Model specification with formulas. 
Exmaple: transformation(y) ~ trend() + season(period="day") + X
Like the lk() function rules. 

LHS: Responce
Defines the data's responce variable
Specificaiton of transformations (with automatic back transformation)

RHS: Specials
Model specific specia functions
Exogenous regressors 


Plotting temperutere on time and demand on time and stacking to show visually relationships is recomended. 

tsbl_elec <- tsibbledata::vic_elec %>% filter(Date < ymd("2014-03-01"))
fbl_elec_fit <- tsbl_elec %>%
  model(ARIMA(Demand ~ WorkDay + Temperature + I(Temperature^2),
  pdq(1,0,1) + PDQ(1,1,1, period = "day")))

# # A mable: 1 model
# model
# <model>
# 1LM w/ ARIMA(1,0,1)(1,1,1)[48] erros 


Extract model information using tidy funcitons using the broom package
augment(mable, ....)
tidy(mable, ...)
glance(mable, ...)
components(mable, ...)

Intresting plot can be made using these.
components(fbl_cafe_fit) %>%
  gather(component, value, level, slope, season) %>%
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(vrs(component), scales = "free_y")
  

Forcast future values
forcast(mable, new_data, h, ...)
Example: fit_cafe_fc <- fbl_cafe_fit %>% forcast(h=24)
fbl_cafe_fc %>% autoplot(vic_cafe)


Electric Demand example
tsbl_elec_new <- tsibbledata::elecdemand %>% 
  filter(index >= ymd("2014-03-01"), index < ymd("2014-03-14"))
fbl_elec_fc <- fbl_elec_fit %>%
  forecast(tsbl_elec_new)

fbl_elec_fc %>% autoplot(tsbl_elec)


  
```{r}
tsbl_elec <- tsibbledata::vic_elec %>% filter(Date < ymd("2014-03-01")) %>% mutate("WorkDay" = wday(Date) )


fbl_elec_fit <- tsbl_elec %>%
  model(arima = ARIMA(Demand ~ WorkDay + Temperature + I(Temperature^2)))
        #, pdq(1,0,1) + PDQ(1,1,1, period = "day"))



tsbl_elec_new <- tsibbledata::vic_elec %>% 
  filter(Date >= ymd("2014-03-01"), Date < ymd("2014-03-14"))


fbl_elec_fc <- fbl_elec_fit %>%
  forecast(tsbl_elec_new)

view(vic_elec)
view(tsbl_elec_new)
```


Accurach evaluation to compare models 
accuracy(mable, measures, ...)
accuracy(fable, new_data, measures, ...)

fbl_cafe_fit %>% accuracy()

Or

fbl_elec_fc %>% accuracy(tsbl_elec_new)


This makes 152 models. 
fbl_cafe_fit 
retail_ets <- tsibbledata::ausretail %>
  ETS(Turnover)


Now use 

Extract(broom::augment)
augment(retail_ets) 

Extract(broom::tidy)
tidy(retail_ets)

Extract(broom::glance)
glance(retail_ets)

Extract(fable::components)
components(retail_ets)

Example:
components(retail_ets) %>%
  filter(Industry == "Cafes, restaurants and takeaway food services") %>%
  ggplot(aes(x = Month, y = level, color = State)) +
  geom_line()
  

Forecast
retail_fc <- retail_ets %>% forecast(h=24)

Evaluate 
retail_ets %>% accuracy()
measures? to check difference in accuracy maybe? 
```{r}

```

Forecasting with Fasster showing electric 

fasster_fit <- tsbl_elec %>%
  fasster(log(Demand) ~ WorkDay %S% (trig(48,16) + poly(1)) + Temperture + I(Temperture^2)) 
  
using exoginest regressors for workday and temperture.

fasster_fc <- fasster_fit %>% 
  forecast(tsbl_elec_new) 
  
  fasster_fc %>% 
    autoplot(tsbl_elec)
    
```{r}


```


Coming Simulate() future paths 

set.seed(20181108)
vic_cafe_sim <- fbl_cafe_fit %>%
  simulate( h = 24, times = 5)
  
  
vic_cafe %>% 
  filter(year(Month) >= 2021) %>% 
  autoplot(Turnover) + 
  geom_line(aes(y = .sim, group = .rep), alpha = 0.3, data = vic_cafe_sim)
  
  
Feture: interpolate() missing values

tsibbledata::olympic_running 

fit a model then interpolate.

olympic_complete <- olympic_running %>% 
  TSLM(Time ~ trend()) %>%
  interpolate(olympic_running) 
  
  refit() allows a model to be applied to a new dataset
  stream() allows a model to be extended using new data
  
  stream is good when you have a model and get additional time series data you just add it and the modeling is redone. 
  
  fasster_stream <- fasster_fit %>% stream(tsbl_elec_new) 
  
Decomposition forecasting
library(tsibblestats)
cafe_dcmp <- vic_cafe %>% STL(log(Turnover)) 


Interval and distribution accuracy
fbl_elec_fc %>% 
accuracy(
  new_data = tsbl_elec_new,
  measures = list(winkler = winkler_score, percentile = perentiale_score)
  
  
)